# Data Science Portfolio
A Repository containing a portfolio of my data science projects completed for academic and self-learning purposes.

## Projects

* ### Machine Learning
  * [Analysis of Bank Marketing Data](https://adamgregg95.github.io/Analysis-of-Bank-Marketing-Data.github.io/) (Python, Spark MLLib, Databricks): Created a classification model to predict whether or not a client will subscribe to a term deposit. After exploring and preprocessing the data, 4 classification algorithms were created. Performances were assessed using Accuracy and AUROC as the evaluation metrics. Random Forest Classifier had the best performance and produced the most optimized model with an AUC score of 0.7871 and an Accuracy of 73.63%.
  
  * [Predicting the Price of a Diamond](https://adamgregg95.github.io/Predicting-the-price-of-a-Diamond.github.io/) (Python, Spark MLLib, Databricks): Created a regression model to predict the price of a diamond. Analyzed, cleaned and transformed the dataset to prepare for modelling. Used 3 regression algorithms (Linear Regression, Random Forest Regressor, and Gradient-Boosted Tree Regressor) and evaluated each models performance by outputting the RMSE and R^2 scores. The Gradient-Boosted Tree Regressor produced the best model as it had the lowest RMSE and the highest R^2 scores on the test data.

  * [Analysis of German Credit Data](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/German%20Credit%20Data/Analysis_of_German_Credit_Data.ipynb) (Python, Pandas, Matplotlib, scikit-learn, Jupyter Notebook): Created a classification model to predict if prospective applicants would be approved a loan or not. Analyzed the data using visualization techniques and preprocessed the data for modelling. Used 3 classification algorithms (Gaussian Naive Bayes, Decision Tree and Logistic Regression). Logistic Regression was chosen for the predictive model as it had the best performance during the 10-fold cross-validation. Achieved a training and testing score of 79%.
  
  * [Census Income Data](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Census%20Income%20Data/Census_Income_Data.ipynb) (Python, Pandas, Matplotlib, scikit-learn, Jupyter Notebook): Leveraging US Census data from 1994, created a classification model to predict whether an individual's gross income is greater than/less than 50K annually. Analyzed, transformed and prepared the data for modelling. Assessed the performance of 6 classification models using 10-Fold Cross Validation and used a form of forward Selection with a Chi-square test of independence for feature selection. Logistic Regression had the best performance accuracy and thus was chosen for the final model which achieved a training and testing score of 82.33% and 81.62% respectively.
  
  * [Quality Predictions in a Mining Process](https://github.com/adamgregg95/Data-Science-Portfolio/tree/master/Quality%20Prediction%20in%20a%20Mining%20Process) (Python, Pandas, Matplotlib, Seaborn, scikit-learn, Jupyter Notebook): Created a regression model to predict the percentage of silica present in iron ore concentrate. Performed exploratory data analysis, transformed and cleaned the data for modelling (See [Analysis](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Quality%20Prediction%20in%20a%20Mining%20Process/Quality_Prediction_in_a_Mining_Process_Analysis.ipynb)). Trained and tested various regression algorithms, and documented performance using RMSE, R^2 and accuracy. The Gradient Boosting Regressor produced the best generalized model (See [Model](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Quality%20Prediction%20in%20a%20Mining%20Process/Quality_Prediction_in_a_Mining_Process_Model.ipynb)).

* ### Data Analysis and Visualization
  * [Titanic Survival Analysis and Model](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Titanic%20Survival%20Analysis%20and%20Model/Titanic%20Survival%20Analysis%20and%20Model.ipynb) (Python, NumPy, Pandas, Matplotlib, scikit-learn, Jupyter Notebook): Analyzed, cleaned, and transformed the data in order to determine what categories of passengers were most likely to survive the Titanic disaster. Used multiple classiﬁcation algorithms to predict the survival rate of the Titanic passengers. Highest accuracy achieved when using a Random Forest; Training Score: 85.8%, Testing Score: 86.6%.
  
  * [Financial Time Series Analysis](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Financial%20Time%20Series%20Analysis/Financial%20Time%20Series%20Analysis.ipynb) (Python, Pandas, Matplotlib, Jupyter Notebook): Analyzed stock market data for Facebook, 3M, IBM, and Amazon over a 60 month period (July 31, 2012 - June 30, 2017). Compared and analyzed auto-correlation plots of the adjusted close and monthly returns for the 4 stocks. Determined the correlation coefficients of the monthly returns for the stocks and displayed these using visualization techniques such as scatter matrices and heat maps. 
  
  * [Bayesian Analysis of Stock Return Data](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Bayesian%20Analysis%20of%20Stock%20Return%20Data.ipynb) (Python, PyMC3, Pandas, Matplotlib, Jupyter Notebook): Used a Baysesian approach for analysis of Apple stock return data. Modelled the data as normal and T-student distributions and estimated distribution parameters using the Markov chain Monte Carlo technique (MCMC). 


- [Space Shuttle Challenger O-ring Regression Model](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Space%20Shuttle%20Challenger%20O-ring%20Regression%20Model/Space%20Shuttle%20Challenger%20O-ring%20Regression%20Model.ipynb) (Python, Pandas, statsmodels, scikit-learn, Jupyter Notebook): Used and compared statsmodels and scikit-learn regression algorithms to predict the number of O-rings that will experience thermal distress for a given ﬂight when the launch temperature is below freezing.
 
- [Generating the Null Distribution and p-value by Simulation](https://github.com/adamgregg95/Data-Science-Portfolio/blob/master/Generating%20the%20Null%20Distribution%20and%20p-value%20by%20Simulation.ipynb) (Python, Matplotlib, Jupyter Notebook): Created a simulation in order to determine whether there is enough evidence to reject the null hypothesis based on changes in the sample proportion due to chance alone.
